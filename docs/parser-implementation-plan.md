# Patchwork Parser Implementation Plan

## Overview

This document breaks down the implementation of the patchwork parser into concrete, testable milestones. Each milestone builds incrementally toward parsing the complete historian examples.

**Architecture:** lalrpop parser generator with external lexer adapter (see [parser-design.md](parser-design.md))

**Validation target:** `examples/historian/*.pw` - four files demonstrating all language features

## Milestones

### Milestone 1: Infrastructure & Token Adapter

**Goal:** Set up the parser crate, lalrpop integration, and token adapter layer.

**Tasks:**

1. **Create parser crate structure**
   - [ ] Create `crates/patchwork-parser/` directory
   - [ ] Add `Cargo.toml` with dependencies: lalrpop, patchwork-lexer
   - [ ] Add lalrpop to build-dependencies
   - [ ] Create `build.rs` to run lalrpop generator

2. **Define AST types (initial minimal set)**
   - [ ] Create `src/ast.rs` with basic types:
     - `Program<'input>` - contains `Vec<Item>`
     - `Item<'input>` - empty enum placeholder for now
     - `Block<'input>` - contains `Vec<Statement>`
     - `Statement<'input>` - empty enum placeholder
     - `Expr<'input>` - empty enum placeholder

3. **Create token adapter**
   - [ ] Create `src/token.rs` with `ParserToken<'input>` enum
     - Map all lexer `TokenType` variants
     - Add lifetime parameter for string references
     - Include variants: Identifier(&'input str), StringText(&'input str), etc.
   - [ ] Create `src/adapter.rs` with `LexerAdapter<'input>` struct
     - Implement `Iterator<Item = Spanned<ParserToken, usize, ParseError>>`
     - Convert lexer tokens to ParserTokens
     - Extract string slices from input for text-carrying tokens
     - Track position for span information
   - [ ] Define `ParseError` type in `src/error.rs`

4. **Create minimal lalrpop grammar**
   - [ ] Create `patchwork.lalrpop` with:
     - `grammar<'input>(input: &'input str);` declaration
     - `extern` block mapping ParserTokens to string literals
     - Single rule: `pub Program: Program<'input> = { => Program { items: vec![] } };`
   - [ ] Verify lalrpop code generation works

5. **Set up public API**
   - [ ] Create `src/lib.rs` with:
     - Module declarations (ast, token, adapter, error)
     - Include generated parser: `mod parser { include!(concat!(env!("OUT_DIR"), "/patchwork.rs")); }`
     - Public parse function: `pub fn parse(input: &str) -> Result<Program, ParseError>`
   - [ ] Re-export AST types

6. **Write basic test**
   - [ ] Test parsing empty input â†’ empty Program
   - [ ] Test adapter converts lexer tokens correctly
   - [ ] Verify build chain works (lexer â†’ adapter â†’ parser)

**Success criteria:**
- âœ… Parser crate builds successfully
- âœ… lalrpop generates parser code
- âœ… Can parse empty input without errors
- âœ… Token adapter correctly converts lexer output

---

### Milestone 2: Top-Level Items & Block Structure

**Goal:** Parse top-level declarations (import, skill, task, fun) and recognize block boundaries.

**Tasks:**

1. **Extend AST for top-level items**
   - [ ] Add to `Item` enum:
     - `Import(ImportDecl)`
     - `Skill(SkillDecl)`
     - `Task(TaskDecl)`
     - `Function(FunctionDecl)`
   - [ ] Define declaration structs:
     - `ImportDecl<'input>` - path: `ImportPath`
     - `SkillDecl<'input>` - name, params, body
     - `TaskDecl<'input>` - name, params, body
     - `FunctionDecl<'input>` - name, params, body
     - `Param<'input>` - name: `&'input str`

2. **Add grammar rules for imports**
   - [ ] `ImportDecl`: `"import" ImportPath`
   - [ ] `ImportPath`: Parse dotted paths and `./{}` syntax
     - Simple path: `std.log`
     - Relative multi-import: `./{analyst, narrator}`
   - [ ] Test: `import std.log` parses correctly
   - [ ] Test: `import ./{analyst, narrator, scribe}` parses correctly

3. **Add grammar rules for declarations**
   - [ ] `SkillDecl`: `"skill" identifier "(" ParamList ")" Block`
   - [ ] `TaskDecl`: `"task" identifier "(" ParamList ")" Block`
   - [ ] `FunctionDecl`: `"fun" identifier "(" ParamList ")" Block`
   - [ ] `ParamList`: Comma-separated identifiers
   - [ ] `Block`: `"{" Statement* "}"`
   - [ ] `Statement`: Placeholder - return dummy statement for now

4. **Test top-level parsing**
   - [ ] Test: Parse `skill foo() {}`
   - [ ] Test: Parse `task bar(a, b, c) {}`
   - [ ] Test: Parse `fun baz(x) {}`
   - [ ] Test: Parse multiple items in sequence
   - [ ] Test: Parse main.pw structure (declarations only, ignore body content)

**Success criteria:**
- âœ… Can parse all top-level item types
- âœ… Recognizes skill/task/fun with parameter lists
- âœ… Recognizes block boundaries (braces)
- âœ… Can parse historian main.pw overall structure

---

### Milestone 3: Simple Statements

**Goal:** Parse variable declarations, expression statements, and control flow.

**Tasks:**

1. **Extend Statement enum**
   - [ ] Add variants:
     - `VarDecl { name: &'input str, type_ann: Option<TypeExpr>, init: Option<Expr> }`
     - `Expr(Expr)`
     - `If { condition: Expr, then_block: Block, else_block: Option<Block> }`
     - `For { var: &'input str, iter: Expr, body: Block }`
     - `While { condition: Expr, body: Block }`
     - `Return(Option<Expr>)`
     - `Succeed`
     - `Fail`
     - `Break`

2. **Add grammar rules for statements**
   - [ ] `VarDecl`: `"var" identifier (":" TypeExpr)? ("=" Expr)?`
   - [ ] `ExprStmt`: `Expr ";"?` (semicolons optional)
   - [ ] `If`: `"if" Expr Block ("else" Block)?`
   - [ ] `For`: `"for" "var" identifier "in" Expr Block`
   - [ ] `While`: `"while" "(" Expr ")" Block`
   - [ ] `Return`: `"return" Expr?`
   - [ ] `Succeed`: `"succeed"`
   - [ ] `Fail`: `"fail"`
   - [ ] `Break`: `"break"`

3. **Add placeholder for TypeExpr**
   - [ ] Define `TypeExpr<'input>` enum with minimal variants:
     - `Name(&'input str)` - for `string`, `int`, etc.
     - Details deferred to Milestone 7

4. **Add minimal Expr placeholder**
   - [ ] Add `Expr::Identifier(&'input str)` variant
   - [ ] Add `Expr::Placeholder` for unparsed expressions
   - [ ] Grammar rule: `Expr = { identifier => Expr::Identifier(<>) }`

5. **Test statement parsing**
   - [ ] Test: `var x`
   - [ ] Test: `var x = y`
   - [ ] Test: `var x: string = y`
   - [ ] Test: `if cond { ... }`
   - [ ] Test: `if cond { ... } else { ... }`
   - [ ] Test: `for var i in items { ... }`
   - [ ] Test: `while (true) { ... }`
   - [ ] Test: `return` and `return value`
   - [ ] Test: `succeed`, `fail`, `break`

**Success criteria:**
- âœ… All statement types parse correctly
- âœ… Blocks can contain statement sequences
- âœ… Can parse control flow with nested blocks
- âœ… Variable declarations with optional type annotations

---

### Milestone 4: Basic Expressions

**Goal:** Parse literals, binary operations, function calls, and member access.

**Tasks:**

1. **Extend Expr enum with literals**
   - [ ] Add variants:
     - `Identifier(&'input str)`
     - `Number(&'input str)`
     - `String(StringLiteral)` (simple version without interpolation)
     - `True`
     - `False`

2. **Add operators and complex expressions**
   - [ ] Add variants:
     - `Binary { op: BinOp, left: Box<Expr>, right: Box<Expr> }`
     - `Unary { op: UnOp, operand: Box<Expr> }`
     - `Call { callee: Box<Expr>, args: Vec<Expr> }`
     - `Member { object: Box<Expr>, field: &'input str }`
     - `Index { object: Box<Expr>, index: Box<Expr> }`

3. **Define operator enums**
   - [ ] `BinOp`: Add, Sub, Mul, Div, Eq, NotEq, Lt, Gt, And, Or, Assign, Pipe, Range
   - [ ] `UnOp`: Not, Neg

4. **Add expression grammar rules**
   - [ ] Literals: identifier, number, string (no interpolation yet), true, false
   - [ ] Binary operations with precedence:
     - Pipe: `||` (lowest)
     - Logical: `&&`, `||`
     - Comparison: `==`, `!=`, `<`, `>`
     - Arithmetic: `+`, `-`, `*`, `/`
     - Range: `...`
   - [ ] Unary: `!`, `-`
   - [ ] Call: `Expr "(" (Expr ("," Expr)*)? ")"`
   - [ ] Member: `Expr "." identifier`
   - [ ] Parenthesized: `"(" Expr ")"`

5. **Define StringLiteral (simple version)**
   - [ ] `StringLiteral<'input>` struct with single text field (no interpolation)
   - [ ] Grammar: Match StringStart, StringEnd (ignore StringText for now)

6. **Test expression parsing**
   - [ ] Test: Literals (`42`, `"hello"`, `true`, `foo`)
   - [ ] Test: Binary ops (`1 + 2`, `x == y`, `a && b`)
   - [ ] Test: Precedence (`1 + 2 * 3` â†’ correct AST)
   - [ ] Test: Unary (`!x`, `-5`)
   - [ ] Test: Calls (`log(a, b, c)`)
   - [ ] Test: Member access (`commit.num`, `plan.length`)
   - [ ] Test: Combined (`self.receive(timeout)`)
   - [ ] Test: Range (`1...3`)

**Success criteria:**
- âœ… All basic expression types parse
- âœ… Operator precedence correct
- âœ… Can parse complex nested expressions
- âœ… Function calls and method calls work

---

### Milestone 5: Prompt Expressions (Think/Ask/Do)

**Goal:** Parse the unique patchwork prompt expressions.

**Tasks:**

1. **Define PromptBlock AST**
   - [ ] Add `PromptBlock<'input>` struct:
     - `items: Vec<PromptItem>`
   - [ ] Add `PromptItem<'input>` enum:
     - `Text(&'input str)` - raw prompt text
     - `Code(Block)` - embedded `do { ... }`

2. **Extend Expr with prompt variants**
   - [ ] Add to `Expr` enum:
     - `Think { content: PromptBlock, fallback: Option<Box<Expr>> }`
     - `Ask { content: PromptBlock }`
     - `Do(Block)`

3. **Add grammar rules for prompt expressions**
   - [ ] `ThinkExpr`: `"think" "{" PromptBlock "}" ("||" Expr)?`
     - Handle fallback pattern: `think { ... } || ask { ... }`
   - [ ] `AskExpr`: `"ask" "{" PromptBlock "}"`
   - [ ] `DoExpr`: `"do" "{" Statement* "}"`

4. **Parse PromptBlock content**
   - [ ] Collect PromptText tokens into Text items
   - [ ] Recognize `do {` within prompt and create Code item
   - [ ] Handle nested braces correctly (lexer already tracks depth)

5. **Test prompt expression parsing**
   - [ ] Test: Simple think block
     ```
     var x = think {
       What is the answer?
     }
     ```
   - [ ] Test: Simple ask block
     ```
     var approval = ask {
       Do you approve?
     }
     ```
   - [ ] Test: Think with fallback
     ```
     var cmd = think {
       Figure it out
     } || ask {
       What command?
     }
     ```
   - [ ] Test: Prompt with embedded do block
     ```
     think {
       First analyze the problem.
       do {
         var x = read_file()
       }
       Then explain the solution.
     }
     ```
   - [ ] Test: Parse analyst.pw's think and ask expressions

**Success criteria:**
- âœ… Think blocks parse correctly
- âœ… Ask blocks parse correctly
- âœ… Think || ask fallback pattern works
- âœ… Do blocks inside prompts are recognized
- âœ… Can parse analyst.pw prompt expressions

---

### Milestone 6: String Interpolation

**Goal:** Parse strings with `${...}` and `$(...)` interpolation.

**Tasks:**

1. **Update StringLiteral AST**
   - [ ] Change `StringLiteral<'input>` to:
     - `parts: Vec<StringPart>`
   - [ ] Add `StringPart<'input>` enum:
     - `Text(&'input str)`
     - `Interpolation(Expr)`

2. **Parse chunked string tokens**
   - [ ] Grammar rule for interpolated strings:
     - Match sequence: StringStart, (StringText | Expr)*, StringEnd
     - Build StringPart::Text from StringText tokens
     - Build StringPart::Interpolation from expressions between tokens

3. **Handle interpolation contexts**
   - [ ] After StringStart or StringText, check for:
     - Another StringText â†’ add Text part
     - Dollar token â†’ begin interpolation expression
     - StringEnd â†’ finish string
   - [ ] Parse expression after Dollar:
     - Identifier â†’ `$var` form
     - LBrace â†’ `${expr}` form (parse until RBrace)
     - LParen â†’ `$(cmd)` form (parse until RParen)

4. **Test string interpolation**
   - [ ] Test: Simple interpolation `"hello ${name}"`
   - [ ] Test: Multiple interpolations `"${a} and ${b}"`
   - [ ] Test: Bash substitution `"session-$(date)"`
   - [ ] Test: Nested interpolation `"outer ${inner + "nested"}"`
   - [ ] Test: All three forms: `"$id ${expr} $(cmd)"`
   - [ ] Test: historian examples with interpolation:
     - `"historian-${timestamp}"`
     - `"/tmp/${session_id}"`
     - `"${work_dir}/state.json"`

**Success criteria:**
- âœ… String interpolation parses correctly
- âœ… All three forms ($id, ${expr}, $(cmd)) work
- âœ… Nested interpolation handles correctly
- âœ… Historian string examples parse

---

### Milestone 7: Advanced Expressions

**Goal:** Parse arrays, objects, destructuring, await, and bash substitution.

**Tasks:**

1. **Add array and object literals**
   - [ ] Extend `Expr` with:
     - `Array(Vec<Expr>)`
     - `Object(Vec<ObjectField>)`
   - [ ] Define `ObjectField<'input>`:
     - `{ key: &'input str, value: Option<Expr> }` (None for shorthand)
   - [ ] Grammar rules:
     - Array: `"[" (Expr ("," Expr)*)? "]"`
     - Object: `"{" (ObjectField ("," ObjectField)*)? "}"`
     - ObjectField: `identifier (":" Expr)?` (shorthand or full)

2. **Add destructuring patterns**
   - [ ] Define `Pattern<'input>` enum:
     - `Identifier(&'input str)`
     - `Object(Vec<ObjectPatternField>)`
   - [ ] Define `ObjectPatternField<'input>`:
     - `{ key: &'input str, pattern: Pattern, type_ann: Option<TypeExpr> }`
   - [ ] Update VarDecl to use Pattern instead of simple name:
     - `VarDecl { pattern: Pattern, init: Option<Expr> }`
   - [ ] Grammar: `"var" Pattern ("=" Expr)?`

3. **Add await expressions**
   - [ ] Extend `Expr` with:
     - `Await(Box<Expr>)`
   - [ ] Grammar: `"await" Expr`
   - [ ] Handle multiple awaits: `await task a(), b(), c()`
     - Parse as `Await(Call(...))` where args are multiple calls

4. **Add bash substitution**
   - [ ] Extend `Expr` with:
     - `BashSubst(Vec<BashToken>)` (or simpler: `BashSubst(Expr)`)
   - [ ] For now, parse `$(...)` as BashSubst containing token sequence
   - [ ] Later milestone can parse bash syntax if needed

5. **Add output redirection**
   - [ ] Extend `Expr` with:
     - `Pipe { left: Box<Expr>, right: Box<Expr> }` (using `|` operator)
     - `Redirect { expr: Box<Expr>, target: Box<Expr> }` (using `>` operator)
   - [ ] Grammar: Binary operators for `|` and `>`

6. **Test advanced expressions**
   - [ ] Test: Arrays `[1, 2, 3]`, `[{num: 1}, {num: 2}]`
   - [ ] Test: Objects `{x: 1, y: 2}`, `{session_id, timestamp}`
   - [ ] Test: Destructuring `var {x, y} = obj`
   - [ ] Test: Destructuring with types `var {x: string, y: int} = msg`
   - [ ] Test: Nested destructuring `var {commits: [{num, description}]} = plan`
   - [ ] Test: Await `await task foo()`
   - [ ] Test: Multiple awaits `await task a(), b(), c()`
   - [ ] Test: Bash subst `$(date +%Y%m%d)`
   - [ ] Test: Output redirect `cat(obj) > "${file}"`
   - [ ] Test: Parse main.pw's complex expressions

**Success criteria:**
- âœ… Array and object literals parse
- âœ… Object shorthand syntax works
- âœ… Destructuring patterns parse
- âœ… Await expressions work
- âœ… Bash substitution recognized
- âœ… main.pw parses completely

---

### Milestone 8: Type System

**Goal:** Parse type annotations and type declarations.

**Tasks:**

1. **Define TypeExpr AST**
   - [ ] Expand `TypeExpr<'input>` enum:
     - `Name(&'input str)` - simple types like `string`, `int`
     - `Object(Vec<TypeField>)` - object type `{ x: string, y: int }`
     - `Array(Box<TypeExpr>)` - array type `[string]`
     - `Union(Vec<TypeExpr>)` - union type `"success" | "error"`
     - `Literal(&'input str)` - string literal type `"success"`

2. **Define TypeField AST**
   - [ ] `TypeField<'input>` struct:
     - `key: &'input str`
     - `type_expr: TypeExpr`
     - `optional: bool` (for future `key?:` syntax)

3. **Add type declaration**
   - [ ] Extend `Item` with:
     - `TypeDecl(TypeDeclItem)`
   - [ ] Define `TypeDeclItem<'input>`:
     - `name: &'input str`
     - `type_expr: TypeExpr`
   - [ ] Grammar: `"type" identifier "=" TypeExpr`

4. **Add grammar rules for types**
   - [ ] TypeExpr rules:
     - Simple name: `identifier`
     - Object type: `"{" (TypeField ("," TypeField)*)? "}"`
     - Array type: `"[" TypeExpr "]"`
     - Union type: `TypeExpr ("|" TypeExpr)+`
     - Literal type: `string` (for string literal types)
   - [ ] TypeField: `identifier ":" TypeExpr`

5. **Test type parsing**
   - [ ] Test: Simple type `var x: string`
   - [ ] Test: Object type in destructuring `var {x: string, y: int} = msg`
   - [ ] Test: Type declaration
     ```
     type scribe_result = {
       status: "success" | "error",
       commit_hash: string
     }
     ```
   - [ ] Test: Array type `var items: [string]`
   - [ ] Test: Union type `status: "success" | "error"`
   - [ ] Test: Parse narrator.pw's type declarations

**Success criteria:**
- âœ… Type annotations parse in variable declarations
- âœ… Type declarations parse
- âœ… Object types parse
- âœ… Union types parse
- âœ… narrator.pw parses completely with types

---

### Milestone 9: Comments & Annotations

**Goal:** Handle comments and decorator-style annotations.

**Tasks:**

1. **Handle comments in lexer/parser**
   - [ ] Decision: Ignore comments during parsing or preserve in AST?
   - [ ] For now: Lexer already emits Comment tokens, parser ignores them
   - [ ] Future: Add comment preservation for doc generation

2. **Parse decorator annotations**
   - [ ] Recognize patterns like:
     - `# @arg param_name description`
     - `# @color purple`
   - [ ] Option 1: Parse as structured Annotation nodes
   - [ ] Option 2: Keep as Comment strings, parse later
   - [ ] Decision: Start with Option 2 (keep as comments)

3. **Test comment handling**
   - [ ] Test: Comments don't break parsing
   - [ ] Test: Inline comments `var x = 1  # comment`
   - [ ] Test: Block comments before declarations
   - [ ] Test: Parse all historian files with comments preserved/ignored

**Success criteria:**
- âœ… Comments don't interfere with parsing
- âœ… All historian files parse with comments present

---

### Milestone 10: Full Historian Example Validation

**Goal:** Successfully parse all four historian example files and validate AST structure.

**Tasks:**

1. **Parse all example files**
   - [ ] Test: `examples/historian/main.pw` parses completely
   - [ ] Test: `examples/historian/analyst.pw` parses completely
   - [ ] Test: `examples/historian/narrator.pw` parses completely
   - [ ] Test: `examples/historian/scribe.pw` parses completely

2. **Validate AST structure**
   - [ ] Write test helper to dump AST as formatted output
   - [ ] Verify key structures parse correctly:
     - main.pw: skill declaration with await task calls
     - analyst.pw: think/ask expressions, variable destructuring
     - narrator.pw: for loop, type declarations, function definition
     - scribe.pw: while loop, nested do blocks in think

3. **Compare with lexer tests**
   - [ ] Ensure parser tests align with existing lexer tests
   - [ ] Both should successfully process the same examples
   - [ ] Parser produces meaningful AST, not just tokens

4. **Error reporting test**
   - [ ] Test intentionally malformed input
   - [ ] Verify error messages are helpful
   - [ ] Check error position tracking

5. **Performance check**
   - [ ] Parse all four files in reasonable time (<100ms combined)
   - [ ] No unnecessary allocations or copies

**Success criteria:**
- âœ… All four historian files parse without errors
- âœ… AST structure matches expected program semantics
- âœ… Error messages are clear and helpful
- âœ… Parser performance is acceptable

---

## Testing Strategy

### Per-Milestone Testing

Each milestone includes specific tests inline. General approach:

1. **Unit tests** - Test individual grammar rules
   - Example: Test that `"var x = 1"` produces correct VarDecl AST node

2. **Snippet tests** - Test small code fragments
   - Example: Test parsing a simple function declaration

3. **Integration tests** - Test parsing complete files
   - Example: Parse full historian examples

4. **Regression tests** - Previous milestones keep passing
   - Never remove tests from earlier milestones
   - Each new milestone runs all previous tests

### Test Organization

```
crates/patchwork-parser/
â”œâ”€ src/
â”‚  â””â”€ lib.rs              # Inline unit tests
â””â”€ tests/
   â”œâ”€ statements.rs       # Statement parsing tests
   â”œâ”€ expressions.rs      # Expression parsing tests
   â”œâ”€ prompts.rs          # Prompt expression tests
   â”œâ”€ strings.rs          # String interpolation tests
   â””â”€ historian.rs        # Full example tests
```

### Test Helpers

```rust
// Helper to parse and assert success
fn parse_expr(input: &str) -> Expr {
    let result = parse(input).unwrap();
    // Extract expression from program...
}

// Helper to assert parse failure
fn assert_parse_error(input: &str) {
    assert!(parse(input).is_err());
}

// Helper to dump AST for debugging
fn dump_ast(ast: &Program) -> String {
    // Pretty-print AST structure
}
```

## Key Decisions & Patterns

### Decision 1: Precedence Strategy

Use lalrpop's precedence levels for binary operators:
```
Tier 1 (highest): Member access (.), Call (())
Tier 2: Unary (!, -)
Tier 3: Multiplicative (*, /)
Tier 4: Additive (+, -)
Tier 5: Range (...)
Tier 6: Comparison (==, !=, <, >)
Tier 7: Logical AND (&&)
Tier 8: Logical OR (||)
Tier 9: Pipe (|)
Tier 10: Assignment (=)
Tier 11 (lowest): Redirect (>)
```

### Decision 2: String Interpolation Parsing

The lexer emits chunked tokens (StringStart, StringText, StringEnd) with Dollar tokens for interpolation. The parser:
1. Matches StringStart
2. Loops collecting StringText or parsing interpolation expressions
3. Matches StringEnd
4. Builds StringLiteral with parts vector

### Decision 3: Prompt Block Parsing

PromptText tokens come from the lexer as large chunks. The parser:
1. Collects consecutive PromptText tokens into Text items
2. Recognizes Do token + LBrace as start of embedded code
3. Parses the code block
4. Continues collecting prompt text

### Decision 4: Optional Semicolons

Following JavaScript convention, semicolons are optional. The grammar:
- Allows `Expr ";"?` for expression statements
- Doesn't require semicolons after blocks

### Decision 5: Error Recovery

Initial implementation: minimal error recovery
- Let lalrpop's default error handling work
- Focus on clear error messages
- Future: Add error recovery for common mistakes

## Deferred to Future Milestones

These features are NOT in historian examples but may be needed later:

1. **Match expressions** - Pattern matching like Rust
2. **Generics** - Type parameters
3. **Macros** - Code generation
4. **Async/await semantics** - Beyond basic await syntax
5. **Module system** - Beyond basic imports
6. **Operator overloading**
7. **Traits/interfaces**

## Success Metrics

Overall success criteria for the parser implementation:

- âœ… All 10 milestones completed
- âœ… All four historian examples parse successfully
- âœ… AST accurately represents program structure
- âœ… Tests cover all language features
- âœ… Error messages are helpful
- âœ… Parser performance <100ms for historian examples
- âœ… Code is maintainable and well-documented

## Next Steps After Completion

Once the parser is complete:

1. **AST Visitor Pattern** - For traversing and transforming AST
2. **Pretty Printer** - Convert AST back to source code
3. **Semantic Analysis** - Type checking, scope resolution
4. **Interpreter** - Execute patchwork programs
5. **Code Generation** - Compile to target language

But first: let's build the parser! ðŸš€
