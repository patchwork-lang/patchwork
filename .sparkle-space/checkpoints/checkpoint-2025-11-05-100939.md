# Session Checkpoint: UTF-8 Span Tracking Investigation

**Date**: 2025-11-05 10:09:39
**Session**: Deep dive into invalid span tracking bug

## Major Breakthrough

Successfully identified the root cause of the invalid span tracking bug that was causing analyst.pw to fail parsing!

## Investigation Process

1. **Added debug logging** to lexer Dollar, RBrace, and Newline token handlers
2. **Ran test with logging** to see exact sequence of mode transitions and spans
3. **Analyzed the output** and found the problematic Newline at line 79
4. **Examined the source** and discovered multi-byte UTF-8 characters
5. **Verified with xxd** that → (U+2192) is 3 bytes (e2 86 92) but 1 column
6. **Traced the accumulation** of byte offset errors through mode transitions

## Root Cause

**Invalid spans are caused by parlex's UTF-8 position tracking breaking after mode transitions:**

- The lexer tracks positions as line/column (character-based)
- Spans are byte offsets into the input string
- After mode transitions (Code → Prompt → InString and back), the conversion from line/column to byte offsets gets corrupted
- Multi-byte UTF-8 characters cause the position accumulator to go negative
- Result: backwards spans like start=2781, end=2774

### Specific Trigger

Line 79 of analyst.pw contains:
```
- Follows a progression (infrastructure → core → features → polish → tests/docs)
```

This line has 4× → characters (U+2192), each:
- 3 bytes in UTF-8 (e2 86 92)
- But counts as 1 column

Total: 12 bytes but only 4 columns. After multiple Prompt mode transitions, this causes the byte offset calculation to fail.

## Technical Details

**What we learned:**
- parlex uses `lexer.span()` which converts line/column positions to byte offsets
- Mode transitions via `lexer.begin(Mode::X)` happen at different times relative to span capture
- The conversion gets out of sync when multi-byte chars are present after transitions
- This is likely a **parlex framework bug**, not our lexer code

## Files Modified

### Updated Documentation
- `docs/parser-workarounds.md`: Added detailed UTF-8 root cause analysis, byte counts, technical explanation

### Fixed Tests
- `crates/patchwork-lexer/src/lib.rs`:
  - `test_string_interpolation_complex_expression`: Changed `Identifier LParen` → `IdentifierCall`
  - `test_string_interpolation_nested`: Changed `Identifier LParen` → `IdentifierCall`
  - `test_shell_mode_dollar_interpolation`: Changed to test actual pattern `"${...}"` in shell

**Why**: Alex lexer's longest-match means `func(` tokenizes as `IdentifierCall` (5 chars) instead of `func` as `Identifier` (4 chars). This affects all `ID(` patterns.

## Test Status

- **Lexer tests**: 57/57 passing ✅
- **Parser tests**: 95/97 passing
  - `test_backtick_interpolation_in_prompt`: FAILS (code fence issue #5)
  - `test_parse_historian_scribe`: FAILS (multi-line ask issue #6)
- **Example files**:
  - `main.pw`: ✅ parses
  - `narrator.pw`: ✅ parses (109 lines, complex features)
  - `analyst.pw`: ❌ UTF-8 span bug + code fence issue
  - `scribe.pw`: ❌ multi-line ask block issue

## Workarounds Status

**Active Workarounds**: 4
1. Invalid span skipping (adapter.rs:208-213)
2. Defensive span validation (adapter.rs:86-89)
3. Source file spacing: `while(` → `while (` (scribe.pw)
4. Comment style: `//` → `#` (scribe.pw)

**Known Issues Without Workarounds**: 2
5. Code fences in prompts (braces treated as tokens)
6. Multi-line ask blocks (Prompt mode doesn't maintain)

## Options Moving Forward

### Option A: Patch parlex
- **Pros**: Fixes UTF-8 handling properly
- **Cons**: Complex, requires deep parlex internals knowledge, may be time-consuming
- **Effort**: High (weeks?)

### Option B: Accept workaround
- **Pros**: Already implemented, logs warnings, parser continues
- **Cons**: Loses tokens with invalid spans, not a proper fix
- **Effort**: Zero (done)

### Option C: Different lexer
- **Pros**: Might have better UTF-8 handling, fresh start
- **Cons**: Would need to rewrite lexer, lose parlex mode support
- **Effort**: High (rewrite)

### Option D: Move to next phase
- **Pros**: Parser works for 2/4 files, good enough for now
- **Cons**: Leaves issues unfixed
- **Effort**: Zero (proceed with semantic analysis/interpreter)

## Recommendations

**For immediate progress**: Accept Option B or D
- The workaround is effective (95/97 tests pass)
- 2 real-world files parse successfully
- Can focus on semantic analysis, type checking, interpreter
- Come back to lexer issues later if needed

**For production quality**: Consider Option A
- UTF-8 support is essential for international users
- The → character is just one example; any multi-byte chars will fail
- Proper fix enables robust text processing

## Next Session Starting Point

**If continuing lexer work:**
- Investigate parlex source code for position tracking
- Look for UTF-8 byte offset conversion bugs
- Test fixes with analyst.pw

**If moving to next phase:**
- Start semantic analysis (symbol tables, scope resolution)
- Design type checking system
- Plan interpreter architecture
- Come back to lexer when production-ready quality needed
